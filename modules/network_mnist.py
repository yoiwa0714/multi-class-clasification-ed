"""
ED-Genuine MNISTå°‚ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹
Isamu Kaneko's Error Diffusion Learning Algorithm implementation
Based on C code pat[5]: One-Hot encoding for multi-class classification

ã€ed_genuine.prompt.md æº–æ‹ å®Ÿè£…ã€‘
- MNIST/Fashion-MNIST ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå°‚ç”¨æ‹¡å¼µ
- ç‹¬ç«‹å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ 
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶å¾¡å¯¾å¿œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æ©Ÿèƒ½
"""

import numpy as np
import time
import threading
from typing import Optional, Tuple, Dict, Any

# å¤–éƒ¨ä¾å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import matplotlib.pyplot as plt
    from tqdm import tqdm
    HAS_VISUALIZATION = True
except ImportError:
    HAS_VISUALIZATION = False

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ä¾å­˜
from .ed_core import EDGenuine


class EDNetworkMNIST(EDGenuine):
    """
    MNISTç”¨EDæ³•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ‹¡å¼µã‚¯ãƒ©ã‚¹
    """
    
    def run_classification(self, train_size=None, test_size=None, epochs=None, 
                          random_state=42, enable_visualization=None, use_fashion_mnist=None):
        """
        MNIST/Fashion-MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹åˆ†é¡ã‚’å®Ÿè¡Œ - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¯¾å¿œ
        Args:
            train_size: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼ˆNoneã®å ´åˆhyperparamsã‹ã‚‰å–å¾—ï¼‰
            test_size: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼ˆNoneã®å ´åˆhyperparamsã‹ã‚‰å–å¾—ï¼‰
            epochs: ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆNoneã®å ´åˆhyperparamsã‹ã‚‰å–å¾—ï¼‰
            random_state: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
            enable_visualization: å¯è¦–åŒ–æœ‰åŠ¹/ç„¡åŠ¹ï¼ˆNoneã®å ´åˆhyperparamsã‹ã‚‰å–å¾—ï¼‰
            use_fashion_mnist: Fashion-MNISTä½¿ç”¨ãƒ•ãƒ©ã‚°ï¼ˆNoneã®å ´åˆhyperparamsã‹ã‚‰å–å¾—ï¼‰
        Returns:
            dict: çµæœçµ±è¨ˆ
        """
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å€¤ã‚’å–å¾—ï¼ˆå®‰å…¨ãªã‚¢ã‚¯ã‚»ã‚¹ï¼‰
        train_size = train_size or getattr(self.hyperparams, 'train_samples', 1000)
        test_size = test_size or getattr(self.hyperparams, 'test_samples', 200)
        epochs = epochs or getattr(self.hyperparams, 'epochs', 10)
        if enable_visualization is None:
            enable_visualization = getattr(self.hyperparams, 'enable_visualization', False)
        if use_fashion_mnist is None:
            use_fashion_mnist = getattr(self.hyperparams, 'fashion_mnist', False)
        
        dataset_name = "Fashion-MNIST" if use_fashion_mnist else "MNIST"
        print("=" * 60)
        print(f"{dataset_name}åˆ†é¡å­¦ç¿’ é–‹å§‹ - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¯¾å¿œç‰ˆ")
        print("=" * 60)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
        train_inputs, train_labels, test_inputs, test_labels = self.load_dataset(
            train_size=train_size, test_size=test_size, use_fashion_mnist=use_fashion_mnist)
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–ï¼ˆ10ã‚¯ãƒ©ã‚¹åˆ†é¡ç”¨ï¼‰ - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¯¾å¿œ
        self.neuro_init(
            input_size=784,  # 28x28 MNIST/Fashion-MNIST
            num_outputs=10,  # 10ã‚¯ãƒ©ã‚¹
            hidden_size=getattr(self.hyperparams, 'hidden_neurons', 100),  # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—
            hidden2_size=0  # éš ã‚Œå±¤2ã¯ä½¿ç”¨ã—ãªã„
        )
        
        print(f"\nğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹æˆ:")
        print(f"  å…¥åŠ›å±¤: 784æ¬¡å…ƒ (28x28ç”»åƒ)")
        print(f"  ä¸­é–“å±¤: {self.hidden_units}ãƒ¦ãƒ‹ãƒƒãƒˆ")
        print(f"  å‡ºåŠ›å±¤: 10ã‚¯ãƒ©ã‚¹")
        print(f"  ç·ãƒ¦ãƒ‹ãƒƒãƒˆ: {self.total_units}")
        
        # æ¨™æº–ã®EDGenuineãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ä½¿ç”¨
        # MNISTãƒ‡ãƒ¼ã‚¿ã‚’input_data, teacher_dataé…åˆ—ã«å¤‰æ›
        self.num_patterns = len(train_inputs)
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
        for i, inp in enumerate(train_inputs):
            inp_flat = inp.flatten().astype(float)
            for j, val in enumerate(inp_flat):
                if j < len(self.input_data[i]):
                    self.input_data[i][j] = val
        
        # æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®šï¼ˆ10ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼‰
        for i, label in enumerate(train_labels):
            for out_idx in range(10):
                if out_idx == label:
                    self.teacher_data[i][out_idx] = 1.0
                else:
                    self.teacher_data[i][out_idx] = 0.0
        
        if getattr(self.hyperparams, 'verbose', False):
            print("âœ… MNISTãƒ‡ãƒ¼ã‚¿è¨­å®šå®Œäº†: {}ãƒ‘ã‚¿ãƒ¼ãƒ³".format(self.num_patterns))
        
        # EDæ³•æ€§èƒ½æœ€é©åŒ–: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚éã‚¼ãƒ­é‡ã¿äº‹å‰è¨ˆç®—
        if getattr(self.hyperparams, 'verbose', False):
            print("âš¡ EDæ³•æœ€é©åŒ–: éã‚¼ãƒ­é‡ã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹äº‹å‰è¨ˆç®—ä¸­...")
        self._precompute_nonzero_weights()
        if getattr(self.hyperparams, 'verbose', False):
            print("âœ… æœ€é©åŒ–å®Œäº†: å­¦ç¿’é€Ÿåº¦å‘ä¸Š")
        
        # å­¦ç¿’å®Ÿè¡Œæº–å‚™
        if not getattr(self.hyperparams, 'quiet_mode', False):
            print(f"\nğŸ¯ å­¦ç¿’é–‹å§‹: {epochs}ã‚¨ãƒãƒƒã‚¯")
        
        # çµæœä¿å­˜ãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
        # NOTE: LearningResultsBufferã¯åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        import sys
        import os
        sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
        from multi_ed_v020 import LearningResultsBuffer
        results_buffer = LearningResultsBuffer(len(train_inputs), len(test_inputs), epochs)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–è¨­å®šï¼ˆå­¦ç¿’é–‹å§‹æ™‚ç‚¹ã§è¡¨ç¤ºï¼‰
        visualizer = None
        confusion_visualizer = None
        if enable_visualization and HAS_VISUALIZATION:
            print("ğŸ¨ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æº–å‚™ä¸­...")
            # NOTE: å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹ã¯åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
            from multi_ed_v020 import RealtimeLearningVisualizer, RealtimeConfusionMatrixVisualizer
            visualizer = RealtimeLearningVisualizer(max_epochs=epochs, save_dir=getattr(self.hyperparams, 'save_fig', None))
            visualizer.setup_plots()
            
            # æ··åŒè¡Œåˆ—å¯è¦–åŒ–ï¼ˆè¨“ç·´é–‹å§‹æ™‚ç‚¹ã‹ã‚‰è¡¨ç¤ºï¼‰
            confusion_visualizer = RealtimeConfusionMatrixVisualizer(
                num_classes=10, window_size=(800, 600), save_dir=getattr(self.hyperparams, 'save_fig', None))
            confusion_visualizer.setup_plots()
            
            print("âœ… å¯è¦–åŒ–ã‚°ãƒ©ãƒ•è¡¨ç¤ºå®Œäº† - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å¾…æ©Ÿä¸­")
        
        start_time = time.time()
        
        epoch_accuracies = []
        train_errors = []
        test_accuracies = []
        
        # ã‚¨ãƒãƒƒã‚¯å…¨ä½“é€²æ—ãƒãƒ¼ï¼ˆä¸Šæ®µï¼‰ - quietãƒ¢ãƒ¼ãƒ‰æ™‚ã¯æŠ‘åˆ¶
        if getattr(self.hyperparams, 'quiet_mode', False):
            # quietãƒ¢ãƒ¼ãƒ‰: é€²æ—ãƒãƒ¼ãªã—
            for epoch in range(epochs):
                epoch_start = time.time()
                
                # æœ€é©åŒ–æ¸ˆã¿å­¦ç¿’ã‚¨ãƒãƒƒã‚¯å®Ÿè¡Œï¼ˆãƒŸãƒ‹ãƒãƒƒãƒå¯¾å¿œï¼‰
                # ed_genuine.prompt.mdæº–æ‹ : å­¦ç¿’ä¸­ã«äºˆæ¸¬â†’ä¿å­˜â†’å­¦ç¿’ã®é †åº
                
                # ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒ1ãªã‚‰å¾“æ¥æ‰‹æ³•ã€ãã‚Œä»¥å¤–ã¯ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’
                batch_size = getattr(self.hyperparams, 'batch_size', 1)
                if batch_size == 1:
                    avg_error, _ = self.train_epoch_with_buffer(
                        results_buffer, epoch, train_inputs, train_labels, 
                        test_inputs, test_labels, show_progress=False, 
                        epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d}")
                else:
                    # ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’å®Ÿè¡Œï¼ˆé‡‘å­å‹‡æ°ç†è«–æ‹¡å¼µï¼‰
                    avg_error, _ = self.train_epoch_with_minibatch(
                        results_buffer, epoch, train_inputs, train_labels, 
                        test_inputs, test_labels, batch_size,
                        show_progress=False, epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d} (batch={batch_size})")
                
                # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰é«˜é€Ÿå–å¾—ï¼ˆåŠ¹ç‡çš„ç²¾åº¦è¨ˆç®—æ‰‹æ³•ä½¿ç”¨ï¼‰
                # ğŸ¯ ã€v0.1.6é«˜é€ŸåŒ–ã€‘åŠ¹ç‡çš„ç²¾åº¦ãƒ»èª¤å·®ç®—å‡ºï¼ˆ3æ¬¡å…ƒé…åˆ—ãƒ™ãƒ¼ã‚¹ï¼‰
                # ed_genuine.prompt.mdæº–æ‹ ï¼šNumPyé…åˆ—æ¼”ç®—ã«ã‚ˆã‚‹é«˜é€Ÿè¨ˆç®—
                train_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'train')
                test_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'test')
                train_error = results_buffer.get_epoch_error_efficient(epoch, 'train')
                test_error = results_buffer.get_epoch_error_efficient(epoch, 'test')
                
                # ğŸ¯ ã€v0.1.6æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‘èª¤å·®ç®—å‡ºæ–¹å¼ã®æ€§èƒ½æ¯”è¼ƒï¼ˆåˆå›ã‚¨ãƒãƒƒã‚¯ã®ã¿ï¼‰
                if epoch == 0 and getattr(self.hyperparams, 'verbose', False):
                    benchmark_results = results_buffer.benchmark_error_calculation_methods(epoch, 'train')
                    speedup = benchmark_results['speedup']
                    print(f"ğŸ“Š èª¤å·®ç®—å‡ºæ€§èƒ½: å¾“æ¥æ–¹å¼ vs 3æ¬¡å…ƒé…åˆ—ãƒ™ãƒ¼ã‚¹ = {speedup:.1f}xé«˜é€ŸåŒ–")
                
                # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                epoch_accuracies.append(test_accuracy)
                train_errors.append(train_error)
                test_accuracies.append(test_accuracy)
                
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æ›´æ–°
                if visualizer:
                    visualizer.update(epoch + 1, train_accuracy, test_accuracy, train_error, test_error)
                
                # æ··åŒè¡Œåˆ—å¯è¦–åŒ–æ›´æ–°ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ»ã‚¨ãƒãƒƒã‚¯æ¯ï¼‰
                if confusion_visualizer:
                    test_true_labels = np.array(results_buffer.test_true_labels[epoch])
                    test_pred_labels = np.array(results_buffer.test_predicted_labels[epoch])
                    confusion_visualizer.update(epoch, test_true_labels, test_pred_labels)
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: é€²æ—ãƒãƒ¼è¡¨ç¤º
            if HAS_VISUALIZATION:
                with tqdm(total=epochs, desc="å…¨ä½“é€²æ—", position=0, leave=True) as epoch_pbar:
                    for epoch in range(epochs):
                        epoch_start = time.time()
                        
                        # æœ€é©åŒ–æ¸ˆã¿å­¦ç¿’ã‚¨ãƒãƒƒã‚¯å®Ÿè¡Œï¼ˆãƒŸãƒ‹ãƒãƒƒãƒå¯¾å¿œï¼‰
                        # ed_genuine.prompt.mdæº–æ‹ : å­¦ç¿’ä¸­ã«äºˆæ¸¬â†’ä¿å­˜â†’å­¦ç¿’ã®é †åº
                        
                        # ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒ1ãªã‚‰å¾“æ¥æ‰‹æ³•ã€ãã‚Œä»¥å¤–ã¯ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’
                        batch_size = getattr(self.hyperparams, 'batch_size', 1)
                        if batch_size == 1:
                            avg_error, _ = self.train_epoch_with_buffer(
                                results_buffer, epoch, train_inputs, train_labels, 
                                test_inputs, test_labels, show_progress=True, 
                                epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d}")
                        else:
                            # ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’å®Ÿè¡Œï¼ˆé‡‘å­å‹‡æ°ç†è«–æ‹¡å¼µï¼‰
                            avg_error, _ = self.train_epoch_with_minibatch(
                                results_buffer, epoch, train_inputs, train_labels, 
                                test_inputs, test_labels, batch_size,
                                show_progress=True, epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d} (batch={batch_size})")
                        
                        # ===== çµ±ä¸€çš„ç²¾åº¦ãƒ»èª¤å·®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼ˆed_genuine.prompt.mdæº–æ‹ ï¼‰ =====
                        # é«˜é€ŸåŒ–: çµ±ä¸€ãƒ‡ãƒ¼ã‚¿è¨ˆç®—ã‚’æœ€çµ‚ã‚¨ãƒãƒƒã‚¯ã¾ãŸã¯å¯è¦–åŒ–æ™‚ã®ã¿ã«åˆ¶é™
                        need_unified_data = (epoch == epochs - 1) or visualizer or confusion_visualizer
                        
                        if need_unified_data:
                            # ã‚¨ãƒãƒƒã‚¯å®Œäº†æ™‚ã«ç²¾åº¦ãƒ»èª¤å·®ã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                            results_buffer.compute_and_cache_epoch_metrics(epoch)
                            
                            # çµ±ä¸€çš„ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã™ã¹ã¦ã®è¡¨ç¤ºç®‡æ‰€ã§åŒã˜å€¤ã‚’ä½¿ç”¨ï¼‰
                            unified_data = results_buffer.get_unified_progress_display_data(epoch)
                            train_accuracy = unified_data['train_accuracy']
                            test_accuracy = unified_data['test_accuracy']
                            train_error = unified_data['train_error']
                            test_error = unified_data['test_error']
                        else:
                            # é«˜é€ŸåŒ–: ä¸­é–“ã‚¨ãƒãƒƒã‚¯ã§ã¯ç°¡æ˜“è¨ˆç®—
                            train_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'train') * 100
                            test_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'test') * 100
                            train_error = results_buffer.get_epoch_error_efficient(epoch, 'train')
                            test_error = results_buffer.get_epoch_error_efficient(epoch, 'test')
                        
                        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                        epoch_accuracies.append(test_accuracy)
                        train_errors.append(train_error)
                        test_accuracies.append(test_accuracy)
                        
                        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æ›´æ–°ï¼ˆçµ±ä¸€ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ - 0-1ç¯„å›²ã«å¤‰æ›ï¼‰
                        if visualizer:
                            # å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ ã¯0-1ç¯„å›²ã‚’æœŸå¾…ã™ã‚‹ãŸã‚å¤‰æ›
                            viz_train_acc = train_accuracy / 100.0  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã‹ã‚‰0-1ç¯„å›²ã«å¤‰æ›
                            viz_test_acc = test_accuracy / 100.0
                            visualizer.update(epoch + 1, viz_train_acc, viz_test_acc, train_error, test_error)
                        
                        # æ··åŒè¡Œåˆ—å¯è¦–åŒ–æ›´æ–°ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ»ã‚¨ãƒãƒƒã‚¯æ¯ï¼‰
                        if confusion_visualizer:
                            test_true_labels = np.array(results_buffer.test_true_labels[epoch])
                            test_pred_labels = np.array(results_buffer.test_predicted_labels[epoch])
                            confusion_visualizer.update(epoch, test_true_labels, test_pred_labels)
                        
                        epoch_time = time.time() - epoch_start
                        
                        # é€²æ—æƒ…å ±æ›´æ–°ï¼ˆed_genuine.prompt.mdæº–æ‹  - çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
                        epoch_pbar.set_postfix({
                            'è¨“ç·´ç²¾åº¦': f'{train_accuracy:.1f}%',
                            'ãƒ†ã‚¹ãƒˆç²¾åº¦': f'{test_accuracy:.1f}%',
                            'è¨“ç·´èª¤å·®': f'{train_error:.3f}',
                            'ãƒ†ã‚¹ãƒˆèª¤å·®': f'{test_error:.3f}',
                            'æ™‚é–“': f'{epoch_time:.1f}s'
                        })
                        epoch_pbar.update(1)
            else:
                # tqdmãŒä½¿ç”¨ã§ããªã„å ´åˆã®ä»£æ›¿å®Ÿè£…
                for epoch in range(epochs):
                    epoch_start = time.time()
                    
                    if self.hyperparams.batch_size == 1:
                        avg_error, _ = self.train_epoch_with_buffer(
                            results_buffer, epoch, train_inputs, train_labels, 
                            test_inputs, test_labels, show_progress=False, 
                            epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d}")
                    else:
                        avg_error, _ = self.train_epoch_with_minibatch(
                            results_buffer, epoch, train_inputs, train_labels, 
                            test_inputs, test_labels, self.hyperparams.batch_size,
                            show_progress=False, epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d} (batch={self.hyperparams.batch_size})")
                    
                    train_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'train')
                    test_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'test')
                    train_error = results_buffer.get_epoch_error_efficient(epoch, 'train')
                    test_error = results_buffer.get_epoch_error_efficient(epoch, 'test')
                    
                    if epoch == 0 and self.hyperparams.verbose:
                        benchmark_results = results_buffer.benchmark_error_calculation_methods(epoch, 'train')
                        speedup = benchmark_results['speedup']
                        print(f"ğŸ“Š èª¤å·®ç®—å‡ºæ€§èƒ½: å¾“æ¥æ–¹å¼ vs 3æ¬¡å…ƒé…åˆ—ãƒ™ãƒ¼ã‚¹ = {speedup:.1f}xé«˜é€ŸåŒ–")
                    
                    epoch_accuracies.append(test_accuracy)
                    train_errors.append(train_error)
                    test_accuracies.append(test_accuracy)
                    
                    if visualizer:
                        visualizer.update(epoch + 1, train_accuracy, test_accuracy, train_error, test_error)
                    
                    if confusion_visualizer:
                        test_true_labels = np.array(results_buffer.test_true_labels[epoch])
                        test_pred_labels = np.array(results_buffer.test_predicted_labels[epoch])
                        confusion_visualizer.update(epoch, test_true_labels, test_pred_labels)
                    
                    epoch_time = time.time() - epoch_start
                    print(f"ã‚¨ãƒãƒƒã‚¯ {epoch+1:2d}/{epochs}: è¨“ç·´ç²¾åº¦={train_accuracy:.3f}, ãƒ†ã‚¹ãƒˆç²¾åº¦={test_accuracy:.3f}, æ™‚é–“={epoch_time:.1f}s")
        
        # å¯è¦–åŒ–çµ‚äº†å‡¦ç†ï¼ˆed_genuine.prompt.mdæº–æ‹  - 5ç§’é–“è¡¨ç¤ºã¾ãŸã¯ã‚­ãƒ¼å…¥åŠ›çµ‚äº†ï¼‰
        if visualizer and not self.hyperparams.quiet_mode:
            print("âœ… å­¦ç¿’å®Œäº† - æœ€çµ‚ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºä¸­...")
            # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã§ã‚°ãƒ©ãƒ•ã‚’æ›´æ–°
            visualizer.fig.canvas.draw()
            visualizer.fig.canvas.flush_events()
            
            print("å¯è¦–åŒ–ã‚°ãƒ©ãƒ•è¡¨ç¤ºä¸­... (5ç§’å¾Œè‡ªå‹•çµ‚äº†ã€ã¾ãŸã¯Enterã‚­ãƒ¼ã§å³åº§ã«çµ‚äº†)")
            
            # 5ç§’é–“è¡¨ç¤ºã¾ãŸã¯ã‚­ãƒ¼å…¥åŠ›ã§ã®çµ‚äº†å‡¦ç†
            
            def countdown_timer():
                """5ç§’ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³é–¢æ•°"""
                time.sleep(5)
                return True
            
            def wait_for_input():
                """Enterå…¥åŠ›å¾…æ©Ÿé–¢æ•°"""
                try:
                    input()  # Enterã‚­ãƒ¼å¾…æ©Ÿ
                    return True
                except:
                    return False
            
            try:
                # ã‚¿ã‚¤ãƒãƒ¼ã¨ã‚­ãƒ¼å…¥åŠ›ã‚’ä¸¦è¡Œå‡¦ç†
                timer_thread = threading.Thread(target=countdown_timer)
                timer_thread.daemon = True
                timer_thread.start()
                
                # Enterå…¥åŠ›ã¾ãŸã¯ã‚¿ã‚¤ãƒãƒ¼çµ‚äº†ã‚’å¾…æ©Ÿ
                input_thread = threading.Thread(target=wait_for_input)
                input_thread.daemon = True
                input_thread.start()
                
                # ã©ã¡ã‚‰ã‹æ—©ã„æ–¹ã§çµ‚äº†
                start_time_wait = time.time()
                while timer_thread.is_alive():
                    if not input_thread.is_alive():
                        print("Enterã‚­ãƒ¼å…¥åŠ›ã«ã‚ˆã‚Šçµ‚äº†ã—ã¾ã™")
                        break
                    if HAS_VISUALIZATION:
                        plt.pause(0.1)  # ã‚°ãƒ©ãƒ•è¡¨ç¤ºç¶­æŒ
                    if time.time() - start_time_wait >= 5:
                        break
                else:
                    print("5ç§’çµŒéã«ã‚ˆã‚Šè‡ªå‹•çµ‚äº†ã—ã¾ã™")
                
            except KeyboardInterrupt:
                print("\nCtrl+Cã«ã‚ˆã‚Šçµ‚äº†ã—ã¾ã™")
            finally:
                # å›³è¡¨ä¿å­˜ï¼ˆ--save-figã‚ªãƒ—ã‚·ãƒ§ãƒ³æœ‰åŠ¹æ™‚ï¼‰
                if self.hyperparams.save_fig:
                    visualizer.save_figure()
                    if confusion_visualizer:
                        confusion_visualizer.save_figure()
                
                visualizer.close()
                if confusion_visualizer:
                    confusion_visualizer.close()
        
        total_time = time.time() - start_time
        
        # æœ€çµ‚è©•ä¾¡
        if not self.hyperparams.quiet_mode:
            print(f"\n{'='*60}")
            print("MNISTåˆ†é¡å­¦ç¿’ å®Œäº†")
            print(f"{'='*60}")
        
        final_accuracy = epoch_accuracies[-1]
        max_accuracy = max(epoch_accuracies)
        
        # æœ€çµ‚çµæœç®—å‡ºï¼ˆè¨“ç·´ç²¾åº¦ã¨ãƒ†ã‚¹ãƒˆç²¾åº¦ï¼‰
        train_accuracy = final_accuracy  # ã‚¨ãƒãƒƒã‚¯ç²¾åº¦ã¯ç¾åœ¨ãƒ†ã‚¹ãƒˆç²¾åº¦ã¨ã—ã¦è¨ˆç®—ã•ã‚Œã¦ã„ã‚‹
        test_accuracy = final_accuracy   # é©åˆ‡ãªåˆ†é›¢ãŒå¿…è¦ãªå ´åˆã¯åˆ¥é€”è¨ˆç®—
        
        if self.hyperparams.quiet_mode:
            # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒç”¨ã®ç°¡æ½”å‡ºåŠ›
            print(f"è¨“ç·´ç²¾åº¦: {train_accuracy:.1f}%")
            print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.1f}%")
        else:
            # é€šå¸¸ã®è©³ç´°å‡ºåŠ›
            print(f"ğŸ“ˆ å­¦ç¿’çµæœ:")
            print(f"  æœ€çµ‚ç²¾åº¦: {final_accuracy:.3f}")
            print(f"  æœ€é«˜ç²¾åº¦: {max_accuracy:.3f}")
            print(f"  ç·å­¦ç¿’æ™‚é–“: {total_time:.1f}ç§’")
            print(f"  å¹³å‡ã‚¨ãƒãƒƒã‚¯æ™‚é–“: {total_time/epochs:.1f}ç§’")
        
        # æ··åŒè¡Œåˆ—è¡¨ç¤ºï¼ˆ--vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨--quietã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«å¿œã˜ãŸè¡¨ç¤ºåˆ¶å¾¡ï¼‰
        if not self.hyperparams.quiet_mode:
            if enable_visualization:
                # --vizæœ‰ã‚Š: ã‚°ãƒ©ãƒ•è¡¨ç¤º
                results_buffer.display_confusion_matrix('train', epoch=-1, save_dir=self.hyperparams.save_fig)
            else:
                # --vizç„¡ã—: æ–‡å­—ãƒ™ãƒ¼ã‚¹è¡¨ç¤º
                results_buffer._display_confusion_matrix_console('train', epoch=-1)
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºï¼ˆ--profileã‚ªãƒ—ã‚·ãƒ§ãƒ³æœ‰åŠ¹æ™‚ï¼‰
        if self.hyperparams.enable_profiling:
            self.profiler.print_detailed_report()
        
        # çµæœçµ±è¨ˆã‚’è¿”ã™ï¼ˆãƒãƒƒãƒ•ã‚¡ã‚‚å«ã‚€ï¼‰
        return {
            'final_accuracy': final_accuracy,
            'max_accuracy': max_accuracy,
            'epoch_accuracies': epoch_accuracies,
            'total_time': total_time,
            'train_size': train_size,
            'test_size': test_size,
            'epochs': epochs,
            'network_size': self.total_units,
            'results_buffer': results_buffer  # æ··åŒè¡Œåˆ—ç”¨ãƒ‡ãƒ¼ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
        }
