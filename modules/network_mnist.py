"""
ED-Genuine MNISTå°‚ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹
Isamu Kaneko's Error Diffusion Learning Algorithm implementation
Based on C code pat[5]: One-Hot encoding for multi-class classification

ã€ed_genuine.prompt.md æº–æ‹ å®Ÿè£…ã€‘
-            visualizer = RealtimeLe            # æ··åŒè¡Œåˆ—å¯è¦–åŒ–ï¼ˆè¨“ç·´é–‹å§‹æ™‚ç‚¹ã‹ã‚‰è¡¨ç¤ºï¼‰
            confusion_visualizer = RealtimeConfusionMatrixVisualizer(
                num_classes=10, window_size=(800, 600), save_dir=getattr(self.hyperparams, 'save_fig', None))
            confusion_visualizer.setup_plots()
                          # ğŸ¯ ed_multi.prompt.mdæº–æ‹ ï¼šæ··åŒè¡Œåˆ—è¡¨ç¤ºï¼ˆã‚¨ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—å®Œäº†å¾Œã«ç§»å‹•ï¼‰
                    # ç”»é¢å´©ã‚Œã‚’é˜²ããŸã‚ã€ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°å¾Œã«è¡¨ç¤º
                    # if not getattr(self.hyperparams, 'quiet_mode', False) and not enable_visualization and epoch == epochs - 1:
                    #     # æ–‡å­—ãƒ™ãƒ¼ã‚¹è¡¨ç¤ºã§ã®ã¿å®Ÿè¡Œï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºæ™‚ã¯å­¦ç¿’å®Œäº†å¾Œã®ã¿ï¼‰
                    #     results_buffer.display_confusion_matrix_single_epoch('test', epoch) 
            # ğŸ¯ ed_multi.prompt.mdæº–æ‹ ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒœãƒƒã‚¯ã‚¹è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿è¨­å®š
            ed_params = {
                'learning_rate': self.hyperparams.learning_rate,
                'amine': self.hyperparams.amine,
                'diffusion': self.hyperparams.diffusion,
                'sigmoid': self.hyperparams.sigmoid,
                'weight1': self.hyperparams.weight1,
                'weight2': self.hyperparams.weight2
            }
            exec_params = {
                'train_samples': self.hyperparams.train_samples,
                'test_samples': self.hyperparams.test_samples,
                'epochs': self.hyperparams.epochs,
                'hidden': str(self.hyperparams.hidden),
                'batch_size': self.hyperparams.batch_size,
                'seed': getattr(self.hyperparams, 'seed', 'Random')
            }
            # ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ç¢ºèª
            print(f"ğŸ” ãƒ‡ãƒãƒƒã‚° - EDæ³•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {ed_params}")
            print(f"ğŸ” ãƒ‡ãƒãƒƒã‚° - å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {exec_params}")
            confusion_visualizer.set_parameters(ed_params, exec_params)
            
            # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³å¯è¦–åŒ–ï¼ˆv0.2.4æ–°æ©Ÿèƒ½ï¼‰
            # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
            # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–
                'learning_rate': self.hyperparams.learning_rate,
                'amine': self.hyperparams.amine,
                'diffusion': self.hyperparams.diffusion,
                'sigmoid': self.hyperparams.sigmoid,
                'weight1': self.hyperparams.weight1,
                'weight2': self.hyperparams.weight2
            }
            exec_params = {
                'train_samples': self.hyperparams.train_samples,
                'test_samples': self.hyperparams.test_samples,
                'epochs': self.hyperparams.epochs,
                'hidden': str(self.hyperparams.hidden),
                'batch_size': self.hyperparams.batch_size,
                'seed': getattr(self.hyperparams, 'seed', 'Random')
            }
            # ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ç¢ºèª
            print(f"ğŸ” ãƒ‡ãƒãƒƒã‚° - EDæ³•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {ed_params}")
            print(f"ğŸ” ãƒ‡ãƒãƒƒã‚° - å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {exec_params}")
            confusion_visualizer.set_parameters(ed_params, exec_params)
            
            # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³å¯è¦–åŒ–ï¼ˆv0.2.4æ–°æ©Ÿèƒ½ï¼‰
            # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
            # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–ion-MNIST ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå°‚ç”¨æ‹¡å¼µ
- ç‹¬ç«‹å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ 
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶å¾¡å¯¾å¿œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æ©Ÿèƒ½
"""

import numpy as np
import time
import threading
from typing import Optional, Tuple, Dict, Any

# å¤–éƒ¨ä¾å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import matplotlib.pyplot as plt
    from tqdm import tqdm
    HAS_VISUALIZATION = True
except ImportError:
    HAS_VISUALIZATION = False

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ä¾å­˜
from .ed_core import EDGenuine


class EDNetworkMNIST(EDGenuine):
    """
    MNISTç”¨EDæ³•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ‹¡å¼µã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, hyperparams):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯¾å¿œï¼‰"""
        super().__init__(hyperparams)
        self.heatmap_callback = None  # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºç”¨ã®ç¾åœ¨ã®ã‚µãƒ³ãƒ—ãƒ«æƒ…å ±
        self.current_sample_info = {
            'epoch': 0,
            'sample_idx': 0,
            'true_label': -1,
            'predicted_label': -1,
            'pattern_idx': 0,
            'input_data': None  # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜ã—ã¦åŒæœŸã‚’ç¢ºä¿
        }
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°é–“éš”ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³æ•°å˜ä½ï¼‰
        self.heatmap_update_interval = 5  # 5ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯ã«æ›´æ–°ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
    
    def set_heatmap_callback(self, callback):
        """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šï¼ˆEDHeatmapIntegrationé€£æºç”¨ï¼‰ - ed_multi.prompt.mdæº–æ‹ """
        self.heatmap_callback = callback
        print("âœ… ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šå®Œäº†")
    
    def update_current_sample_info(self, epoch, sample_idx, true_label, predicted_label=None, pattern_idx=None, input_data=None):
        """ç¾åœ¨ã®ã‚µãƒ³ãƒ—ãƒ«æƒ…å ±ã‚’æ›´æ–°ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºç”¨ãƒ»å…¥åŠ›ãƒ‡ãƒ¼ã‚¿åŒæœŸå¯¾å¿œï¼‰"""
        self.current_sample_info.update({
            'epoch': epoch,
            'sample_idx': sample_idx,
            'true_label': true_label,
            'predicted_label': predicted_label if predicted_label is not None else -1,
            'pattern_idx': pattern_idx if pattern_idx is not None else sample_idx,
            'input_data': input_data  # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¨ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«åŒæœŸã®ãŸã‚
        })
    
    def get_current_sample_info(self):
        """ç¾åœ¨ã®ã‚µãƒ³ãƒ—ãƒ«æƒ…å ±ã‚’å–å¾—ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºç”¨ï¼‰"""
        return self.current_sample_info.copy()
    
    def _initialize_data_arrays(self, train_inputs, train_labels, test_inputs, test_labels):
        """ãƒ‡ãƒ¼ã‚¿é…åˆ—ã‚’åˆæœŸåŒ–ï¼ˆå‹•çš„ç”Ÿæˆå¯¾å¿œï¼‰"""
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’input_dataé…åˆ—ã«è¨­å®š
        for i, (input_vec, label) in enumerate(zip(train_inputs, train_labels)):
            # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿è¨­å®šï¼ˆ784æ¬¡å…ƒã‚’é…åˆ—ã«æ ¼ç´ï¼‰
            flattened_input = input_vec.flatten() if hasattr(input_vec, 'flatten') else input_vec
            for j, val in enumerate(flattened_input):
                if i < self.num_patterns and j < self.input_units:
                    self.input_data[i][j] = float(val)
            
            # æ•™å¸«ãƒ‡ãƒ¼ã‚¿è¨­å®šï¼ˆOne-Hotç¬¦å·åŒ–ï¼‰
            if i < self.num_patterns:
                for k in range(self.output_units):
                    self.teacher_data[i][k] = 1.0 if k == int(label) else 0.0
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚‚åŒæ§˜ã«è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        # ï¼ˆé€šå¸¸ã®EDæ³•ã§ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼‰
    
    def generate_epoch_data(self, epoch: int) -> tuple:
        """ã‚¨ãƒãƒƒã‚¯æ¯ã®ç‹¬ç«‹è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å‹•çš„ç”Ÿæˆï¼ˆEDGenuineã‚¯ãƒ©ã‚¹çµŒç”±ï¼‰"""
        return super().generate_epoch_data(epoch)
    
    def run_classification(self, enable_visualization=False, use_fashion_mnist=False, 
                         train_size=1000, test_size=200, epochs=3, random_state=None):
        """
        MNIST/Fashion-MNISTåˆ†é¡å­¦ç¿’ã‚’å®Ÿè¡Œ

        Args:
            enable_visualization: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ã®æœ‰åŠ¹åŒ–
            use_fashion_mnist: Fashion-MNISTã‚’ä½¿ç”¨ã™ã‚‹ã‹
            train_size: 1ã‚¨ãƒãƒƒã‚¯å½“ãŸã‚Šã®è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°
            test_size: 1ã‚¨ãƒãƒƒã‚¯å½“ãŸã‚Šã®ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°
            epochs: ã‚¨ãƒãƒƒã‚¯æ•°
            random_state: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰

        Returns:
            dict: å­¦ç¿’çµæœãƒ‡ãƒ¼ã‚¿
        """
        dataset_name = "Fashion-MNIST" if use_fashion_mnist else "MNIST"
        if not getattr(self.hyperparams, 'quiet_mode', False):
            print("=" * 60)
            print(f"{dataset_name}åˆ†é¡å­¦ç¿’ é–‹å§‹ - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¯¾å¿œç‰ˆ")
            print("=" * 60)
        
        # ï¿½ ã€ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã€‘å‹•çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹å¼
        # ã‚¨ãƒãƒƒã‚¯æ¯ã«ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ç”Ÿæˆã—ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å¤§å¹…å‰Šæ¸›
        
        if not getattr(self.hyperparams, 'quiet_mode', False):
            print(f"ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰è¨­å®šï¼ˆãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç‰ˆï¼‰:")
            print(f"  ã‚¨ãƒãƒƒã‚¯æ¯ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_size}ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå‹•çš„ç”Ÿæˆï¼‰")
            print(f"  ã‚¨ãƒãƒƒã‚¯æ¯ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_size}ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå›ºå®šã‚»ãƒƒãƒˆï¼‰")
            print(f"  ç·ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
            print(f"  ğŸ¯ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: äº‹å‰æº–å‚™é‡ã‚’æœ€å°åŒ–ã—ã¦ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ã‚’å›é¿")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆå‹•çš„ç”ŸæˆåŸºç›¤ã®ã¿æº–å‚™ï¼‰
        # ed_multi.prompt.mdæº–æ‹ : ã‚¨ãƒãƒƒã‚¯æ¯ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿè¡Œæ™‚ç”Ÿæˆ
        train_inputs, train_labels, test_inputs, test_labels = self.load_dataset(
            train_size=train_size, test_size=test_size,  # ã‚¨ãƒãƒƒã‚¯å˜ä½ã‚µã‚¤ã‚ºã§åŸºç›¤æº–å‚™
            use_fashion_mnist=use_fashion_mnist, total_epochs=epochs)
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–ï¼ˆ10ã‚¯ãƒ©ã‚¹åˆ†é¡ç”¨ï¼‰ - å¤šå±¤å¯¾å¿œ
        hidden_layers = getattr(self.hyperparams, 'hidden_layers', [100])
        
        if len(hidden_layers) == 1:
            # å˜å±¤ã®å ´åˆ
            hidden_size = hidden_layers[0]
            hidden2_size = 0
            print(f"ğŸ“Š å˜å±¤æ§‹æˆ: éš ã‚Œå±¤{hidden_size}ãƒ¦ãƒ‹ãƒƒãƒˆ")
        else:
            # å¤šå±¤ã®å ´åˆ: ç·éš ã‚Œãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã‚’è¨ˆç®—
            hidden_size = sum(hidden_layers)
            hidden2_size = 0  # ed_multi.prompt.mdæº–æ‹ ã§ã¯ hidden2_size ã¯ä½¿ç”¨ã—ãªã„
            print(f"ğŸ“Š å¤šå±¤æ§‹æˆ: éš ã‚Œå±¤{'â†’'.join(map(str, hidden_layers))} (ç·è¨ˆ{hidden_size}ãƒ¦ãƒ‹ãƒƒãƒˆ)")
        
        self.neuro_init(
            input_size=784,  # 28x28 MNIST/Fashion-MNIST
            num_outputs=10,  # 10ã‚¯ãƒ©ã‚¹
            hidden_size=hidden_size,  # å˜å±¤/å¤šå±¤ã«å¿œã˜ãŸéš ã‚Œãƒ¦ãƒ‹ãƒƒãƒˆæ•°
            hidden2_size=hidden2_size  # éš ã‚Œå±¤2ã¯ä½¿ç”¨ã—ãªã„
        )
        
        print(f"\nğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹æˆ:")
        print(f"  å…¥åŠ›å±¤: 784æ¬¡å…ƒ (28x28ç”»åƒ)")
        print(f"  ä¸­é–“å±¤: {hidden_size}ãƒ¦ãƒ‹ãƒƒãƒˆ {'(å¤šå±¤åˆè¨ˆ)' if len(hidden_layers) > 1 else '(å˜å±¤)'}")
        if len(hidden_layers) > 1:
            print(f"  å¤šå±¤è©³ç´°: {'â†’'.join(map(str, hidden_layers))}")
        print(f"  å‡ºåŠ›å±¤: 10ã‚¯ãƒ©ã‚¹")
        print(f"  ç·ãƒ¦ãƒ‹ãƒƒãƒˆ: {self.total_units}")
        
        # ğŸš€ ã€æœ€é©åŒ–ã€‘å‹•çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«å¯¾å¿œã™ã‚‹åˆæœŸåŒ–
        # train_inputsãŒç©ºé…åˆ—ãªã®ã§ã€ã‚¨ãƒãƒƒã‚¯æ¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°ã‚’ä½¿ç”¨
        self.num_patterns = train_size  # ã‚¨ãƒãƒƒã‚¯æ¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°ã‚’ä½¿ç”¨
        
        # ğŸ”§ é‡è¦: å‹•çš„ç”Ÿæˆã®å ´åˆã‚‚åˆæœŸãƒ‡ãƒ¼ã‚¿è¨­å®šãŒå¿…è¦  
        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚¨ãƒãƒƒã‚¯å®Ÿè¡Œæ™‚ã«è¨­å®šã™ã‚‹ãŒã€é…åˆ—ã‚µã‚¤ã‚ºåˆæœŸåŒ–ã®ãŸã‚ä»®ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
        if len(train_inputs) == 0:
            # ä»®ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆé…åˆ—ã‚µã‚¤ã‚ºç¢ºä¿ã®ãŸã‚ï¼‰
            dummy_train_inputs = np.zeros((train_size, 784))
            dummy_train_labels = np.zeros(train_size)
            self._initialize_data_arrays(dummy_train_inputs, dummy_train_labels, test_inputs, test_labels)
        else:
            # é€šå¸¸ã®åˆæœŸåŒ–
            self._initialize_data_arrays(train_inputs, train_labels, test_inputs, test_labels)
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
        for i, inp in enumerate(train_inputs):
            # é…åˆ—ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆed_genuine.prompt.mdæº–æ‹ ã®å®‰å…¨æ€§ç¢ºä¿ï¼‰
            if i >= len(self.input_data):
                # å‹•çš„ãƒ¡ãƒ¢ãƒªç®¡ç†ã«ã‚ˆã‚Šè‡ªå‹•çš„ã«å¯¾å¿œæ¸ˆã¿
                break
                
            inp_flat = inp.flatten().astype(float)
            for j, val in enumerate(inp_flat):
                if j < len(self.input_data[i]):
                    self.input_data[i][j] = val
        
        # æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®šï¼ˆ10ã‚¯ãƒ©ã‚¹åˆ†é¡ï¼‰
        for i, label in enumerate(train_labels):
            # é…åˆ—ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆed_genuine.prompt.mdæº–æ‹ ã®å®‰å…¨æ€§ç¢ºä¿ï¼‰
            if i >= len(self.teacher_data):
                # å‹•çš„ãƒ¡ãƒ¢ãƒªç®¡ç†ã«ã‚ˆã‚Šè‡ªå‹•çš„ã«å¯¾å¿œæ¸ˆã¿
                break
                
            for out_idx in range(10):
                if out_idx == label:
                    self.teacher_data[i][out_idx] = 1.0
                else:
                    self.teacher_data[i][out_idx] = 0.0
        
        if getattr(self.hyperparams, 'verbose', False):
            print("âœ… MNISTãƒ‡ãƒ¼ã‚¿è¨­å®šå®Œäº†: {}ãƒ‘ã‚¿ãƒ¼ãƒ³".format(self.num_patterns))
        
        # EDæ³•æ€§èƒ½æœ€é©åŒ–: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚éã‚¼ãƒ­é‡ã¿äº‹å‰è¨ˆç®—
        if getattr(self.hyperparams, 'verbose', False):
            print("âš¡ EDæ³•æœ€é©åŒ–: éã‚¼ãƒ­é‡ã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹äº‹å‰è¨ˆç®—ä¸­...")
        self._precompute_nonzero_weights()
        if getattr(self.hyperparams, 'verbose', False):
            print("âœ… æœ€é©åŒ–å®Œäº†: å­¦ç¿’é€Ÿåº¦å‘ä¸Š")
        
        # å­¦ç¿’å®Ÿè¡Œæº–å‚™
        if not getattr(self.hyperparams, 'quiet_mode', False):
            print(f"\nğŸ¯ å­¦ç¿’é–‹å§‹: {epochs}ã‚¨ãƒãƒƒã‚¯")
        
        # çµæœä¿å­˜ãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
        # ğŸ”§ ã€ä¿®æ­£ã€‘å‹•çš„ç”Ÿæˆå¯¾å¿œ: ã‚¨ãƒãƒƒã‚¯æ¯ã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’ä½¿ç”¨
        import sys
        import os
        sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
        from modules.performance import LearningResultsBuffer
        # å‹•çš„ç”Ÿæˆã®å ´åˆã¯è¨­å®šå€¤ã‚’ä½¿ç”¨ã€é€šå¸¸ã®å ´åˆã¯é…åˆ—é•·ã‚’ä½¿ç”¨
        actual_train_size = train_size if len(train_inputs) == 0 else len(train_inputs)
        results_buffer = LearningResultsBuffer(actual_train_size, len(test_inputs), epochs)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–è¨­å®šï¼ˆå­¦ç¿’é–‹å§‹æ™‚ç‚¹ã§è¡¨ç¤ºï¼‰
        visualizer = None
        confusion_visualizer = None
        neuron_visualizer = None
        neuron_adapter = None
        
        if enable_visualization and HAS_VISUALIZATION:
            print("ğŸ¨ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æº–å‚™ä¸­...")
            
            # å¾“æ¥ã®å­¦ç¿’å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
            from modules.visualization import RealtimeLearningVisualizer, RealtimeConfusionMatrixVisualizer
            visualizer = RealtimeLearningVisualizer(max_epochs=epochs, save_dir=getattr(self.hyperparams, 'save_fig', None))
            visualizer.setup_plots()
            
            # æ··åŒè¡Œåˆ—å¯è¦–åŒ–ï¼ˆè¨“ç·´é–‹å§‹æ™‚ç‚¹ã‹ã‚‰è¡¨ç¤ºï¼‰
            confusion_visualizer = RealtimeConfusionMatrixVisualizer(
                num_classes=10, window_size=(800, 600), save_dir=getattr(self.hyperparams, 'save_fig', None))
            confusion_visualizer.setup_plots()
            
            # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³å¯è¦–åŒ–ï¼ˆv0.2.4æ–°æ©Ÿèƒ½ï¼‰
            # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
            # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–
            neuron_visualizer = None
            neuron_adapter = None
            
            # ğŸ¯ ed_multi.prompt.mdæº–æ‹ ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒœãƒƒã‚¯ã‚¹è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿è¨­å®š
            ed_params = {
                'learning_rate': getattr(self.hyperparams, 'learning_rate', 0.5),
                'threshold': getattr(self.hyperparams, 'initial_amine', 0.8),  # initial_amineã‚’ä½¿ç”¨
                'threshold_alpha': getattr(self.hyperparams, 'diffusion_rate', 0.95),  # diffusion_rateã‚’ä½¿ç”¨
                'threshold_beta': getattr(self.hyperparams, 'sigmoid_threshold', 0.85),  # sigmoid_thresholdã‚’ä½¿ç”¨
                'threshold_gamma': getattr(self.hyperparams, 'initial_weight_1', 0.75)  # initial_weight_1ã‚’ä½¿ç”¨
            }
            exec_params = {
                'epochs': epochs,
                'batch_size': getattr(self.hyperparams, 'batch_size', 32),
                'num_layers': len(hidden_layers),  # hidden_layersã‚’ä½¿ç”¨
                'train_size': len(train_inputs),
                'test_size': len(test_inputs)
            }
            
            # ğŸ¯ ed_multi.prompt.mdæº–æ‹ ï¼šä¸¡æ–¹ã®å¯è¦–åŒ–ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
            confusion_visualizer.set_parameters(ed_params, exec_params)
            visualizer.set_parameters(ed_params, exec_params)
            
            print("âœ… å¯è¦–åŒ–ã‚°ãƒ©ãƒ•è¡¨ç¤ºå®Œäº† - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å¾…æ©Ÿä¸­")
        
        start_time = time.time()
        
        epoch_accuracies = []
        train_errors = []
        test_accuracies = []
        
        # ã€é‡è¦ã€‘ã‚¨ãƒãƒƒã‚¯æ¯ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆ1ã‚¨ãƒãƒƒã‚¯å½“ãŸã‚Šã®ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼‰
        epoch_train_size = train_size  # 1ã‚¨ãƒãƒƒã‚¯å½“ãŸã‚Šã®è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°
        epoch_test_size = test_size    # 1ã‚¨ãƒãƒƒã‚¯å½“ãŸã‚Šã®ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°
        
        # ã‚¨ãƒãƒƒã‚¯å…¨ä½“é€²æ—ãƒãƒ¼ï¼ˆä¸Šæ®µï¼‰ - quietãƒ¢ãƒ¼ãƒ‰æ™‚ã¯æŠ‘åˆ¶
        if getattr(self.hyperparams, 'quiet_mode', False):
            # quietãƒ¢ãƒ¼ãƒ‰: é€²æ—ãƒãƒ¼ãªã—
            for epoch in range(epochs):
                epoch_start = time.time()
                
                # ã€é‡è¦ã€‘ã‚¨ãƒãƒƒã‚¯æ¯ã«ç‹¬ç«‹ã—ãŸãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’å–å¾—ï¼ˆè¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆä¸¡æ–¹ï¼‰
                epoch_start_idx = epoch * epoch_train_size
                epoch_end_idx = (epoch + 1) * epoch_train_size
                epoch_train_inputs = train_inputs[epoch_start_idx:epoch_end_idx]
                epoch_train_labels = train_labels[epoch_start_idx:epoch_end_idx]
                
                # ğŸ›¡ï¸ ä¿®æ­£: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿é…åˆ—ç¯„å›²åˆ¶é™ãƒ»å¾ªç’°ä½¿ç”¨å‡¦ç†è¿½åŠ 
                test_start_idx = epoch * epoch_test_size
                test_end_idx = (epoch + 1) * epoch_test_size
                
                # é…åˆ—ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼šãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¶…éã—ãªã„ã‚ˆã†åˆ¶é™
                if test_end_idx > len(test_inputs):
                    # ã‚¨ãƒãƒƒã‚¯æ•°ãŒå¤šã„å ´åˆã®å¾ªç’°ä½¿ç”¨ï¼ˆed_multi.prompt.mdæº–æ‹ ã®ç‹¬ç«‹æ€§ç¶­æŒï¼‰
                    test_start_idx = (epoch * epoch_test_size) % len(test_inputs)
                    test_end_idx = min(test_start_idx + epoch_test_size, len(test_inputs))
                    
                    # ä¸è¶³åˆ†ã¯å…ˆé ­ã‹ã‚‰è£œå®Œï¼ˆç‹¬ç«‹æ€§ç¶­æŒã®ãŸã‚ç•°ãªã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨ï¼‰
                    if test_end_idx - test_start_idx < epoch_test_size:
                        remaining_needed = epoch_test_size - (test_end_idx - test_start_idx)
                        epoch_test_inputs = np.concatenate([
                            test_inputs[test_start_idx:test_end_idx],
                            test_inputs[:remaining_needed]
                        ])
                        epoch_test_labels = np.concatenate([
                            test_labels[test_start_idx:test_end_idx], 
                            test_labels[:remaining_needed]
                        ])
                    else:
                        epoch_test_inputs = test_inputs[test_start_idx:test_end_idx]
                        epoch_test_labels = test_labels[test_start_idx:test_end_idx]
                        
                    if self.hyperparams.verbose:
                        print(f"ğŸ”„ ã‚¨ãƒãƒƒã‚¯{epoch+1}: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å¾ªç’°ä½¿ç”¨ [{test_start_idx}:{test_end_idx}] + å…ˆé ­ã‹ã‚‰{remaining_needed if 'remaining_needed' in locals() else 0}ã‚µãƒ³ãƒ—ãƒ«")
                else:
                    epoch_test_inputs = test_inputs[test_start_idx:test_end_idx]
                    epoch_test_labels = test_labels[test_start_idx:test_end_idx]
                
                if self.hyperparams.verbose:
                    print(f"ğŸ¯ ã‚¨ãƒãƒƒã‚¯{epoch+1}: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç¯„å›² [{epoch_start_idx}:{epoch_end_idx}] (ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«{len(epoch_train_inputs)}å€‹)")
                    print(f"ğŸ¯ ã‚¨ãƒãƒƒã‚¯{epoch+1}: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç¯„å›² [{test_start_idx}:{test_end_idx}] (ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«{len(epoch_test_inputs)}å€‹)")
                
                # æœ€é©åŒ–æ¸ˆã¿å­¦ç¿’ã‚¨ãƒãƒƒã‚¯å®Ÿè¡Œï¼ˆãƒŸãƒ‹ãƒãƒƒãƒå¯¾å¿œï¼‰
                # ed_genuine.prompt.mdæº–æ‹ : å­¦ç¿’ä¸­ã«äºˆæ¸¬â†’ä¿å­˜â†’å­¦ç¿’ã®é †åº
                
                # ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒ1ãªã‚‰å¾“æ¥æ‰‹æ³•ã€ãã‚Œä»¥å¤–ã¯ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’
                batch_size = getattr(self.hyperparams, 'batch_size', 1)
                if batch_size == 1:
                    avg_error, _ = self.train_epoch_with_buffer(
                        results_buffer, epoch, epoch_train_inputs, epoch_train_labels, 
                        epoch_test_inputs, epoch_test_labels, show_progress=False, 
                        epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d}")
                else:
                    # ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’å®Ÿè¡Œï¼ˆé‡‘å­å‹‡æ°ç†è«–æ‹¡å¼µï¼‰
                    avg_error, _ = self.train_epoch_with_minibatch(
                        results_buffer, epoch, epoch_train_inputs, epoch_train_labels, 
                        epoch_test_inputs, epoch_test_labels, batch_size,
                        show_progress=False, epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d} (batch={batch_size})")
                
                # ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰é«˜é€Ÿå–å¾—ï¼ˆåŠ¹ç‡çš„ç²¾åº¦è¨ˆç®—æ‰‹æ³•ä½¿ç”¨ï¼‰
                # ğŸ¯ ã€v0.1.6é«˜é€ŸåŒ–ã€‘åŠ¹ç‡çš„ç²¾åº¦ãƒ»èª¤å·®ç®—å‡ºï¼ˆ3æ¬¡å…ƒé…åˆ—ãƒ™ãƒ¼ã‚¹ï¼‰
                # ed_genuine.prompt.mdæº–æ‹ ï¼šNumPyé…åˆ—æ¼”ç®—ã«ã‚ˆã‚‹é«˜é€Ÿè¨ˆç®—
                train_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'train')
                test_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'test')
                train_error = results_buffer.get_epoch_error_efficient(epoch, 'train')
                test_error = results_buffer.get_epoch_error_efficient(epoch, 'test')
                
                # ğŸ¯ ã€v0.1.6æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‘èª¤å·®ç®—å‡ºæ–¹å¼ã®æ€§èƒ½æ¯”è¼ƒï¼ˆåˆå›ã‚¨ãƒãƒƒã‚¯ã®ã¿ï¼‰
                if epoch == 0 and getattr(self.hyperparams, 'verbose', False):
                    benchmark_results = results_buffer.benchmark_error_calculation_methods(epoch, 'train')
                    speedup = benchmark_results['speedup']
                    print(f"ğŸ“Š èª¤å·®ç®—å‡ºæ€§èƒ½: å¾“æ¥æ–¹å¼ vs 3æ¬¡å…ƒé…åˆ—ãƒ™ãƒ¼ã‚¹ = {speedup:.1f}xé«˜é€ŸåŒ–")
                
                # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                epoch_accuracies.append(test_accuracy)
                train_errors.append(train_error)
                test_accuracies.append(test_accuracy)
                
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æ›´æ–°
                if visualizer:
                    visualizer.update(epoch + 1, train_accuracy, test_accuracy, train_error, test_error)
                
                # ED-SNN RealtimeNeuronVisualizeræ›´æ–°ï¼ˆå¤–éƒ¨ã‹ã‚‰è¨­å®šã•ã‚ŒãŸå ´åˆï¼‰
                # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
                # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–
                # if hasattr(self, 'neuron_visualizer') and self.neuron_visualizer is not None:
                #     ... (ç„¡åŠ¹åŒ–)
                
                # æ··åŒè¡Œåˆ—å¯è¦–åŒ–æ›´æ–°ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ»ã‚¨ãƒãƒƒã‚¯æ¯ï¼‰
                if confusion_visualizer:
                    test_true_labels = np.array(results_buffer.test_true_labels[epoch])
                    test_pred_labels = np.array(results_buffer.test_predicted_labels[epoch])
                    confusion_visualizer.update(epoch, test_true_labels, test_pred_labels)
                
                # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³å¯è¦–åŒ–æ›´æ–°ï¼ˆv0.2.4æ–°æ©Ÿèƒ½ãƒ»Quietãƒ¢ãƒ¼ãƒ‰ï¼‰
                # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
                # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–
                # if neuron_visualizer and neuron_adapter:
                #     ... (ç„¡åŠ¹åŒ–)
                
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: é€²æ—ãƒãƒ¼è¡¨ç¤º
            if HAS_VISUALIZATION:
                with tqdm(total=epochs, desc="å…¨ä½“é€²æ—", position=0, leave=True) as epoch_pbar:
                    for epoch in range(epochs):
                        epoch_start = time.time()
                        
                        # ğŸš€ ã€æœ€é©åŒ–ã€‘ã‚¨ãƒãƒƒã‚¯æ¯ã®ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ã‚’å‹•çš„ç”Ÿæˆ
                        # ed_multi.prompt.mdæº–æ‹ ï¼šã‚¨ãƒãƒƒã‚¯æ¯ã«å®Œå…¨ç‹¬ç«‹ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
                        epoch_train_inputs, epoch_train_labels = self.generate_epoch_data(epoch)
                        
                        # ğŸ›¡ï¸ ä¿®æ­£: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿é…åˆ—ç¯„å›²åˆ¶é™ãƒ»å¾ªç’°ä½¿ç”¨å‡¦ç†è¿½åŠ 
                        test_start_idx = epoch * epoch_test_size
                        test_end_idx = (epoch + 1) * epoch_test_size
                        
                        # é…åˆ—ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼šãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¶…éã—ãªã„ã‚ˆã†åˆ¶é™
                        if test_end_idx > len(test_inputs):
                            # ã‚¨ãƒãƒƒã‚¯æ•°ãŒå¤šã„å ´åˆã®å¾ªç’°ä½¿ç”¨ï¼ˆed_multi.prompt.mdæº–æ‹ ã®ç‹¬ç«‹æ€§ç¶­æŒï¼‰
                            test_start_idx = (epoch * epoch_test_size) % len(test_inputs)
                            test_end_idx = min(test_start_idx + epoch_test_size, len(test_inputs))
                            
                            # ä¸è¶³åˆ†ã¯å…ˆé ­ã‹ã‚‰è£œå®Œï¼ˆç‹¬ç«‹æ€§ç¶­æŒã®ãŸã‚ç•°ãªã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨ï¼‰
                            if test_end_idx - test_start_idx < epoch_test_size:
                                remaining_needed = epoch_test_size - (test_end_idx - test_start_idx)
                                epoch_test_inputs = np.concatenate([
                                    test_inputs[test_start_idx:test_end_idx],
                                    test_inputs[:remaining_needed]
                                ])
                                epoch_test_labels = np.concatenate([
                                    test_labels[test_start_idx:test_end_idx], 
                                    test_labels[:remaining_needed]
                                ])
                            else:
                                epoch_test_inputs = test_inputs[test_start_idx:test_end_idx]
                                epoch_test_labels = test_labels[test_start_idx:test_end_idx]
                                
                            if self.hyperparams.verbose:
                                print(f"ğŸ”„ ã‚¨ãƒãƒƒã‚¯{epoch+1}: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å¾ªç’°ä½¿ç”¨ [{test_start_idx}:{test_end_idx}] + å…ˆé ­ã‹ã‚‰{remaining_needed if 'remaining_needed' in locals() else 0}ã‚µãƒ³ãƒ—ãƒ«")
                        else:
                            epoch_test_inputs = test_inputs[test_start_idx:test_end_idx]
                            epoch_test_labels = test_labels[test_start_idx:test_end_idx]
                        
                        if self.hyperparams.verbose and epoch % 10 == 0:
                            print(f"ğŸ¯ ã‚¨ãƒãƒƒã‚¯{epoch+1}: å‹•çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº† (ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«{len(epoch_train_inputs)}å€‹)")
                            print(f"ğŸ¯ ã‚¨ãƒãƒƒã‚¯{epoch+1}: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç¯„å›² [{test_start_idx}:{test_end_idx}] (ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«{len(epoch_test_inputs)}å€‹)")
                        
                        # æœ€é©åŒ–æ¸ˆã¿å­¦ç¿’ã‚¨ãƒãƒƒã‚¯å®Ÿè¡Œï¼ˆãƒŸãƒ‹ãƒãƒƒãƒå¯¾å¿œï¼‰
                        # ed_genuine.prompt.mdæº–æ‹ : å­¦ç¿’ä¸­ã«äºˆæ¸¬â†’ä¿å­˜â†’å­¦ç¿’ã®é †åº
                        
                        # ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒ1ãªã‚‰å¾“æ¥æ‰‹æ³•ã€ãã‚Œä»¥å¤–ã¯ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’
                        batch_size = getattr(self.hyperparams, 'batch_size', 1)
                        if batch_size == 1:
                            avg_error, _ = self.train_epoch_with_buffer(
                                results_buffer, epoch, epoch_train_inputs, epoch_train_labels, 
                                epoch_test_inputs, epoch_test_labels, show_progress=True, 
                                epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d}")
                        else:
                            # ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’å®Ÿè¡Œï¼ˆé‡‘å­å‹‡æ°ç†è«–æ‹¡å¼µï¼‰
                            avg_error, _ = self.train_epoch_with_minibatch(
                                results_buffer, epoch, epoch_train_inputs, epoch_train_labels, 
                                epoch_test_inputs, epoch_test_labels, batch_size,
                                show_progress=True, epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d} (batch={batch_size})")
                        
                        # ===== çµ±ä¸€çš„ç²¾åº¦ãƒ»èª¤å·®ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼ˆed_genuine.prompt.mdæº–æ‹ ï¼‰ =====
                        # é«˜é€ŸåŒ–: çµ±ä¸€ãƒ‡ãƒ¼ã‚¿è¨ˆç®—ã‚’æœ€çµ‚ã‚¨ãƒãƒƒã‚¯ã¾ãŸã¯å¯è¦–åŒ–æ™‚ã®ã¿ã«åˆ¶é™
                        need_unified_data = (epoch == epochs - 1) or visualizer or confusion_visualizer
                        
                        if need_unified_data:
                            # ã‚¨ãƒãƒƒã‚¯å®Œäº†æ™‚ã«ç²¾åº¦ãƒ»èª¤å·®ã‚’è¨ˆç®—ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                            results_buffer.compute_and_cache_epoch_metrics(epoch)
                            
                            # çµ±ä¸€çš„ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆã™ã¹ã¦ã®è¡¨ç¤ºç®‡æ‰€ã§åŒã˜å€¤ã‚’ä½¿ç”¨ï¼‰
                            unified_data = results_buffer.get_unified_progress_display_data(epoch)
                            train_accuracy = unified_data['train_accuracy']
                            test_accuracy = unified_data['test_accuracy']
                            train_error = unified_data['train_error']
                            test_error = unified_data['test_error']
                        else:
                            # é«˜é€ŸåŒ–: ä¸­é–“ã‚¨ãƒãƒƒã‚¯ã§ã¯ç°¡æ˜“è¨ˆç®—
                            train_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'train') * 100
                            test_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'test') * 100
                            train_error = results_buffer.get_epoch_error_efficient(epoch, 'train')
                            test_error = results_buffer.get_epoch_error_efficient(epoch, 'test')
                        
                        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                        epoch_accuracies.append(test_accuracy)
                        train_errors.append(train_error)
                        test_accuracies.append(test_accuracy)
                        
                        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æ›´æ–°ï¼ˆçµ±ä¸€ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ - 0-1ç¯„å›²ã«å¤‰æ›ï¼‰
                        if visualizer:
                            # å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ ã¯0-1ç¯„å›²ã‚’æœŸå¾…ã™ã‚‹ãŸã‚å¤‰æ›
                            viz_train_acc = train_accuracy / 100.0  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã‹ã‚‰0-1ç¯„å›²ã«å¤‰æ›
                            viz_test_acc = test_accuracy / 100.0
                            visualizer.update(epoch + 1, viz_train_acc, viz_test_acc, train_error, test_error)
                        
                        # ED-SNN RealtimeNeuronVisualizeræ›´æ–°ï¼ˆå¤–éƒ¨ã‹ã‚‰è¨­å®šã•ã‚ŒãŸå ´åˆï¼‰
                        # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
                        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–
                        # if hasattr(self, 'neuron_visualizer') and self.neuron_visualizer is not None:
                        #     ... (ç„¡åŠ¹åŒ–)
                        
                        # æ··åŒè¡Œåˆ—å¯è¦–åŒ–æ›´æ–°ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ»ã‚¨ãƒãƒƒã‚¯æ¯ï¼‰
                        if confusion_visualizer:
                            test_true_labels = np.array(results_buffer.test_true_labels[epoch])
                            test_pred_labels = np.array(results_buffer.test_predicted_labels[epoch])
                            confusion_visualizer.update(epoch, test_true_labels, test_pred_labels)
                        
                        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–æ›´æ–°ï¼ˆEDHeatmapIntegrationé€£æºï¼‰ - ed_multi.prompt.mdæº–æ‹ 
                        if hasattr(self, 'heatmap_callback') and self.heatmap_callback is not None:
                            self.heatmap_callback()
                        
                        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³å¯è¦–åŒ–æ›´æ–°ï¼ˆv0.2.4æ–°æ©Ÿèƒ½ï¼‰
                        # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
                        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–
                        # if neuron_visualizer and neuron_adapter:
                        #     ... (ç„¡åŠ¹åŒ–)
                        
                        epoch_time = time.time() - epoch_start
                        
                        # é€²æ—æƒ…å ±æ›´æ–°ï¼ˆed_genuine.prompt.mdæº–æ‹  - çµ±ä¸€ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
                        epoch_pbar.set_postfix({
                            'è¨“ç·´ç²¾åº¦': f'{train_accuracy:.1f}%',
                            'ãƒ†ã‚¹ãƒˆç²¾åº¦': f'{test_accuracy:.1f}%',
                            'è¨“ç·´èª¤å·®': f'{train_error:.3f}',
                            'ãƒ†ã‚¹ãƒˆèª¤å·®': f'{test_error:.3f}',
                            'æ™‚é–“': f'{epoch_time:.1f}s'
                        })
                        epoch_pbar.update(1)
            else:
                # tqdmãŒä½¿ç”¨ã§ããªã„å ´åˆã®ä»£æ›¿å®Ÿè£…
                for epoch in range(epochs):
                    epoch_start = time.time()
                    
                    # ğŸš€ ã€æœ€é©åŒ–ã€‘ã‚¨ãƒãƒƒã‚¯æ¯ã®ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ã‚’å‹•çš„ç”Ÿæˆ
                    # ed_multi.prompt.mdæº–æ‹ ï¼šã‚¨ãƒãƒƒã‚¯æ¯ã«å®Œå…¨ç‹¬ç«‹ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
                    epoch_train_inputs, epoch_train_labels = self.generate_epoch_data(epoch)
                    
                    # ğŸ›¡ï¸ ä¿®æ­£: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿é…åˆ—ç¯„å›²åˆ¶é™ãƒ»å¾ªç’°ä½¿ç”¨å‡¦ç†è¿½åŠ 
                    test_start_idx = epoch * epoch_test_size
                    test_end_idx = (epoch + 1) * epoch_test_size
                    
                    # é…åˆ—ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼šãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¶…éã—ãªã„ã‚ˆã†åˆ¶é™
                    if test_end_idx > len(test_inputs):
                        # ã‚¨ãƒãƒƒã‚¯æ•°ãŒå¤šã„å ´åˆã®å¾ªç’°ä½¿ç”¨ï¼ˆed_multi.prompt.mdæº–æ‹ ã®ç‹¬ç«‹æ€§ç¶­æŒï¼‰
                        test_start_idx = (epoch * epoch_test_size) % len(test_inputs)
                        test_end_idx = min(test_start_idx + epoch_test_size, len(test_inputs))
                        
                        # ä¸è¶³åˆ†ã¯å…ˆé ­ã‹ã‚‰è£œå®Œï¼ˆç‹¬ç«‹æ€§ç¶­æŒã®ãŸã‚ç•°ãªã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨ï¼‰
                        if test_end_idx - test_start_idx < epoch_test_size:
                            remaining_needed = epoch_test_size - (test_end_idx - test_start_idx)
                            epoch_test_inputs = np.concatenate([
                                test_inputs[test_start_idx:test_end_idx],
                                test_inputs[:remaining_needed]
                            ])
                            epoch_test_labels = np.concatenate([
                                test_labels[test_start_idx:test_end_idx], 
                                test_labels[:remaining_needed]
                            ])
                        else:
                            epoch_test_inputs = test_inputs[test_start_idx:test_end_idx]
                            epoch_test_labels = test_labels[test_start_idx:test_end_idx]
                            
                        if self.hyperparams.verbose:
                            print(f"ğŸ”„ ã‚¨ãƒãƒƒã‚¯{epoch+1}: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å¾ªç’°ä½¿ç”¨ [{test_start_idx}:{test_end_idx}] + å…ˆé ­ã‹ã‚‰{remaining_needed if 'remaining_needed' in locals() else 0}ã‚µãƒ³ãƒ—ãƒ«")
                    else:
                        epoch_test_inputs = test_inputs[test_start_idx:test_end_idx]
                        epoch_test_labels = test_labels[test_start_idx:test_end_idx]
                    
                    if self.hyperparams.verbose and epoch % 10 == 0:
                        print(f"ğŸ¯ ã‚¨ãƒãƒƒã‚¯{epoch+1}: å‹•çš„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº† (ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«{len(epoch_train_inputs)}å€‹)")
                        print(f"ğŸ¯ ã‚¨ãƒãƒƒã‚¯{epoch+1}: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç¯„å›² [{test_start_idx}:{test_end_idx}] (ç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«{len(epoch_test_inputs)}å€‹)")
                    
                    if getattr(self.hyperparams, 'batch_size', 1) == 1:
                        avg_error, _ = self.train_epoch_with_buffer(
                            results_buffer, epoch, epoch_train_inputs, epoch_train_labels, 
                            epoch_test_inputs, epoch_test_labels, show_progress=False, 
                            epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d}")
                    else:
                        avg_error, _ = self.train_epoch_with_minibatch(
                            results_buffer, epoch, epoch_train_inputs, epoch_train_labels, 
                            epoch_test_inputs, epoch_test_labels, getattr(self.hyperparams, 'batch_size', 1),
                            show_progress=False, epoch_info=f"ã‚¨ãƒãƒƒã‚¯{epoch+1:2d} (batch={getattr(self.hyperparams, 'batch_size', 1)})")
                    
                    train_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'train')
                    test_accuracy = results_buffer.get_epoch_accuracy_efficient(epoch, 'test')
                    train_error = results_buffer.get_epoch_error_efficient(epoch, 'train')
                    test_error = results_buffer.get_epoch_error_efficient(epoch, 'test')
                    
                    if epoch == 0 and self.hyperparams.verbose:
                        benchmark_results = results_buffer.benchmark_error_calculation_methods(epoch, 'train')
                        speedup = benchmark_results['speedup']
                        print(f"ğŸ“Š èª¤å·®ç®—å‡ºæ€§èƒ½: å¾“æ¥æ–¹å¼ vs 3æ¬¡å…ƒé…åˆ—ãƒ™ãƒ¼ã‚¹ = {speedup:.1f}xé«˜é€ŸåŒ–")
                    
                    epoch_accuracies.append(test_accuracy)
                    train_errors.append(train_error)
                    test_accuracies.append(test_accuracy)
                    
                    if visualizer:
                        visualizer.update(epoch + 1, train_accuracy, test_accuracy, train_error, test_error)
                    
                    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–æ›´æ–°ï¼ˆEDHeatmapIntegrationé€£æºï¼‰ - ed_multi.prompt.mdæº–æ‹ 
                    if hasattr(self, 'heatmap_callback') and self.heatmap_callback is not None:
                        self.heatmap_callback()
                    
                    # ED-SNN RealtimeNeuronVisualizeræ›´æ–°ï¼ˆå¤–éƒ¨ã‹ã‚‰è¨­å®šã•ã‚ŒãŸå ´åˆï¼‰
                    # ed_multi.prompt.mdæº–æ‹ : --vizã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯å­¦ç¿’æ›²ç·šãƒ»æ··åŒè¡Œåˆ—ãƒ»ç²¾åº¦æ¨ç§»ã®ã¿è¡¨ç¤º
                    # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¯è¦–åŒ–ã¯ç„¡åŠ¹åŒ–
                    # if hasattr(self, 'neuron_visualizer') and self.neuron_visualizer is not None:
                    #     ... (ç„¡åŠ¹åŒ–)
                    
                    if confusion_visualizer:
                        test_true_labels = np.array(results_buffer.test_true_labels[epoch])
                        test_pred_labels = np.array(results_buffer.test_predicted_labels[epoch])
                        confusion_visualizer.update(epoch, test_true_labels, test_pred_labels)
                    
                    epoch_time = time.time() - epoch_start
                    print(f"ã‚¨ãƒãƒƒã‚¯ {epoch+1:2d}/{epochs}: è¨“ç·´ç²¾åº¦={train_accuracy:.3f}, ãƒ†ã‚¹ãƒˆç²¾åº¦={test_accuracy:.3f}, æ™‚é–“={epoch_time:.1f}s")
        
        # å¯è¦–åŒ–çµ‚äº†å‡¦ç†ï¼ˆed_genuine.prompt.mdæº–æ‹  - 5ç§’é–“è¡¨ç¤ºã¾ãŸã¯æ‰‹å‹•ã‚¯ãƒ­ãƒ¼ã‚ºï¼‰
        if visualizer and not getattr(self.hyperparams, 'quiet_mode', False):
            print("âœ… å­¦ç¿’å®Œäº† - æœ€çµ‚ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºä¸­...")
            # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã§ã‚°ãƒ©ãƒ•ã‚’æ›´æ–°
            visualizer.fig.canvas.draw()
            visualizer.fig.canvas.flush_events()
            
            print("å¯è¦–åŒ–ã‚°ãƒ©ãƒ•è¡¨ç¤ºä¸­... (5ç§’å¾Œè‡ªå‹•çµ‚äº†ã€ã¾ãŸã¯Enterã‚­ãƒ¼ã§å³åº§ã«çµ‚äº†)")
            
            # 5ç§’é–“è¡¨ç¤ºã¾ãŸã¯ã‚­ãƒ¼å…¥åŠ›ã§ã®çµ‚äº†å‡¦ç†
            
            def countdown_timer():
                """5ç§’ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³é–¢æ•°"""
                time.sleep(5)
                return True
            
            def wait_for_input():
                """Enterå…¥åŠ›å¾…æ©Ÿé–¢æ•°"""
                try:
                    input()  # Enterã‚­ãƒ¼å¾…æ©Ÿ
                    return True
                except:
                    return False
            
            try:
                # å˜ç´”ãª5ç§’å¾…æ©Ÿã¨ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿å¯¾å¿œ
                start_time_wait = time.time()
                
                # 5ç§’é–“å¾…æ©Ÿï¼ˆ0.1ç§’é–“éš”ã§ç¢ºèªï¼‰
                while time.time() - start_time_wait < 5:
                    if HAS_VISUALIZATION:
                        try:
                            import warnings
                            with warnings.catch_warnings():
                                warnings.simplefilter("ignore", UserWarning)
                                plt.pause(0.1)  # ã‚°ãƒ©ãƒ•è¡¨ç¤ºç¶­æŒ
                        except Exception:
                            pass
                    else:
                        time.sleep(0.1)
                
                print("5ç§’çµŒéã«ã‚ˆã‚Šè‡ªå‹•çµ‚äº†ã—ã¾ã™")
                
            except KeyboardInterrupt:
                print("\nCtrl+Cã«ã‚ˆã‚Šçµ‚äº†ã—ã¾ã™")
            finally:
                # å›³è¡¨ä¿å­˜ï¼ˆ--save-figã‚ªãƒ—ã‚·ãƒ§ãƒ³æœ‰åŠ¹æ™‚ï¼‰
                if getattr(self.hyperparams, 'save_fig', False):
                    visualizer.save_figure()
                    if confusion_visualizer:
                        confusion_visualizer.save_figure()
                
                visualizer.close()
                if confusion_visualizer:
                    confusion_visualizer.close()
        
        total_time = time.time() - start_time
        
        # ğŸ¯ æ··åŒè¡Œåˆ—è¡¨ç¤ºï¼ˆã‚¨ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—å®Œäº†å¾Œã€æœ€çµ‚çµæœå‰ï¼‰
        # ed_multi.prompt.mdæº–æ‹ ï¼šãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿è¡¨ç¤ºã€ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼å®Œäº†å¾Œ
        if not getattr(self.hyperparams, 'quiet_mode', False) and not enable_visualization and epochs > 0:
            # æ–‡å­—ãƒ™ãƒ¼ã‚¹è¡¨ç¤ºã§ã®ã¿å®Ÿè¡Œï¼ˆã‚°ãƒ©ãƒ•è¡¨ç¤ºæ™‚ã¯å­¦ç¿’å®Œäº†å¾Œã®ã¿ï¼‰
            print()  # æ”¹è¡Œã§ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨åˆ†é›¢
            results_buffer.display_confusion_matrix_single_epoch('test', epochs - 1)
        
        # ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆè¡¨ç¤ºï¼ˆå­¦ç¿’å®Œäº†å¾Œï¼‰
        self._display_data_usage_statistics()
        
        # æœ€çµ‚è©•ä¾¡
        if not getattr(self.hyperparams, 'quiet_mode', False):
            print(f"\n{'='*60}")
            print("MNISTåˆ†é¡å­¦ç¿’ å®Œäº†")
            print(f"{'='*60}")
        
        final_accuracy = epoch_accuracies[-1]
        max_accuracy = max(epoch_accuracies)
        
        # æœ€çµ‚çµæœç®—å‡ºï¼ˆè¨“ç·´ç²¾åº¦ã¨ãƒ†ã‚¹ãƒˆç²¾åº¦ï¼‰
        train_accuracy = final_accuracy  # ã‚¨ãƒãƒƒã‚¯ç²¾åº¦ã¯ç¾åœ¨ãƒ†ã‚¹ãƒˆç²¾åº¦ã¨ã—ã¦è¨ˆç®—ã•ã‚Œã¦ã„ã‚‹
        test_accuracy = final_accuracy   # é©åˆ‡ãªåˆ†é›¢ãŒå¿…è¦ãªå ´åˆã¯åˆ¥é€”è¨ˆç®—
        
        if getattr(self.hyperparams, 'quiet_mode', False):
            # ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒç”¨ã®ç°¡æ½”å‡ºåŠ›
            print(f"è¨“ç·´ç²¾åº¦: {train_accuracy:.1f}%")
            print(f"ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.1f}%")
        else:
            # é€šå¸¸ã®è©³ç´°å‡ºåŠ›
            print(f"ğŸ“ˆ å­¦ç¿’çµæœ:")
            print(f"  æœ€çµ‚ç²¾åº¦: {final_accuracy:.3f}")
            print(f"  æœ€é«˜ç²¾åº¦: {max_accuracy:.3f}")
            print(f"  ç·å­¦ç¿’æ™‚é–“: {total_time:.1f}ç§’")
            print(f"  å¹³å‡ã‚¨ãƒãƒƒã‚¯æ™‚é–“: {total_time/epochs:.1f}ç§’")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºï¼ˆ--profileã‚ªãƒ—ã‚·ãƒ§ãƒ³æœ‰åŠ¹æ™‚ï¼‰
        if self.hyperparams.enable_profiling:
            self.profiler.print_detailed_report()
        
        # çµæœçµ±è¨ˆã‚’è¿”ã™ï¼ˆãƒãƒƒãƒ•ã‚¡ã‚‚å«ã‚€ï¼‰
        return {
            'final_accuracy': final_accuracy,
            'max_accuracy': max_accuracy,
            'epoch_accuracies': epoch_accuracies,
            'total_time': total_time,
            'train_size': train_size,
            'test_size': test_size,
            'epochs': epochs,
            'network_size': self.total_units,
            'results_buffer': results_buffer  # æ··åŒè¡Œåˆ—ç”¨ãƒ‡ãƒ¼ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
        }

    def _extract_actual_neuron_activities(self):
        """
        EDæ³•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‹ã‚‰å®Ÿéš›ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        ed_multi.prompt.mdæº–æ‹ ã®æ­£ç¢ºãªãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³çŠ¶æ…‹å–å¾—
        
        Returns:
            List[np.ndarray]: å„å±¤ã®ç™ºç«ãƒ‡ãƒ¼ã‚¿ [å…¥åŠ›å±¤, éš ã‚Œå±¤, å‡ºåŠ›å±¤]
        """
        try:
            # EDæ³•ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç¢ºèª
            if not hasattr(self, 'ed_genuine') or self.ed_genuine is None:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
                return [np.zeros(784), np.zeros(128), np.zeros(10)]
            
            # EDæ³•ã®å®Ÿéš›ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³çŠ¶æ…‹é…åˆ—ã‹ã‚‰æŠ½å‡º
            layer_activities = []
            
            # å…¥åŠ›å±¤æ´»å‹•ï¼ˆ784ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰
            # output_inputsé…åˆ—ã®æœ€åˆã®å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰å…¥åŠ›å±¤ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            if hasattr(self.ed_genuine, 'output_inputs') and self.ed_genuine.output_inputs is not None:
                # å…¥åŠ›å±¤ã¯2-785ç•ªç›®ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0,1ã¯ãƒã‚¤ã‚¢ã‚¹ã€2-785ã¯784å€‹ã®å…¥åŠ›ï¼‰
                input_range_start = 2
                input_range_end = input_range_start + 784
                input_activity = []
                
                # ç¬¬0å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å…¥åŠ›å±¤éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å¾Œã®å€¤ã‚’ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¤‰æ›ï¼‰
                for i in range(input_range_start, min(input_range_end, self.ed_genuine.output_inputs.shape[1])):
                    neuron_value = self.ed_genuine.output_inputs[0][i] if i < self.ed_genuine.output_inputs.shape[1] else 0.0
                    # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å€¤ã‚’ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¤‰æ›ï¼ˆé–¾å€¤0.5ï¼‰
                    firing_rate = 1.0 if neuron_value > 0.5 else 0.0
                    input_activity.append(firing_rate)
                
                # 784å€‹ã«èª¿æ•´
                while len(input_activity) < 784:
                    input_activity.append(0.0)
                input_activity = input_activity[:784]
            else:
                input_activity = np.zeros(784)
            
            layer_activities.append(np.array(input_activity))
            
            # éš ã‚Œå±¤æ´»å‹•ï¼ˆ128ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰
            if hasattr(self.ed_genuine, 'output_inputs') and self.ed_genuine.output_inputs is not None:
                # éš ã‚Œå±¤ã¯786-913ç•ªç›®ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆå…¥åŠ›784+ãƒã‚¤ã‚¢ã‚¹2ã®å¾Œï¼‰
                hidden_range_start = 2 + 784  # 786
                hidden_range_end = hidden_range_start + 128  # 914
                hidden_activity = []
                
                for i in range(hidden_range_start, min(hidden_range_end, self.ed_genuine.output_inputs.shape[1])):
                    neuron_value = self.ed_genuine.output_inputs[0][i] if i < self.ed_genuine.output_inputs.shape[1] else 0.0
                    # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å€¤ã‚’ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¤‰æ›ï¼ˆéš ã‚Œå±¤ç”¨é–¾å€¤0.3ï¼‰
                    firing_rate = min(1.0, max(0.0, neuron_value)) if neuron_value > 0.3 else 0.0
                    hidden_activity.append(firing_rate)
                
                # 128å€‹ã«èª¿æ•´
                while len(hidden_activity) < 128:
                    hidden_activity.append(0.0)
                hidden_activity = hidden_activity[:128]
            else:
                hidden_activity = np.zeros(128)
                
            layer_activities.append(np.array(hidden_activity))
            
            # å‡ºåŠ›å±¤æ´»å‹•ï¼ˆ10ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰
            if hasattr(self.ed_genuine, 'output_outputs') and self.ed_genuine.output_outputs is not None:
                output_activity = []
                
                # å„å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»å‹•ã‚’å–å¾—
                for n in range(min(10, self.ed_genuine.output_outputs.shape[0])):
                    # å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æœ€çµ‚å€¤ï¼ˆåˆ†é¡å‡ºåŠ›ï¼‰
                    output_value = self.ed_genuine.output_outputs[n][0] if self.ed_genuine.output_outputs.shape[1] > 0 else 0.0
                    # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å€¤ã‚’ç™ºç«ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¤‰æ›ï¼ˆå‡ºåŠ›å±¤ç”¨é–¾å€¤0.1ï¼‰
                    firing_rate = min(1.0, max(0.0, output_value))
                    output_activity.append(firing_rate)
                
                # 10å€‹ã«èª¿æ•´
                while len(output_activity) < 10:
                    output_activity.append(0.0)
                output_activity = output_activity[:10]
            else:
                output_activity = np.zeros(10)
                
            layer_activities.append(np.array(output_activity))
            
            return layer_activities
            
        except Exception as e:
            print(f"âš ï¸ ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»å‹•æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã™
            return [np.zeros(784), np.zeros(128), np.zeros(10)]
    
    def _display_data_usage_statistics(self):
        """å­¦ç¿’å®Œäº†å¾Œã«MNISTãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆã‚’è¡¨ç¤º"""
        try:
            print(f"\n{'='*60}")
            print("ğŸ“Š MNISTãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆ")
            print(f"{'='*60}")
            
            # åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æƒ…å ±
            if hasattr(self, 'ed_genuine') and hasattr(self.ed_genuine, 'train_original_indices'):
                train_indices = self.ed_genuine.train_original_indices
                test_indices = self.ed_genuine.test_original_indices
                
                print(f"åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æƒ…å ±:")
                print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: {len(train_indices)}")
                print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°: {len(test_indices)}")
                print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿å…ƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¯„å›²: [{train_indices.min()}, {train_indices.max()}]")
                print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å…ƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¯„å›²: [{test_indices.min()}, {test_indices.max()}]")
                
                # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿åˆ†æ
                unique_train = np.unique(train_indices)
                unique_test = np.unique(test_indices)
                print(f"  è¨“ç·´ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿æ•°: {len(unique_train)}")
                print(f"  ãƒ†ã‚¹ãƒˆãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿æ•°: {len(unique_test)}")
                
                # é‡è¤‡ä½¿ç”¨ã®ç¢ºèª
                unique_train_indices, train_counts = np.unique(train_indices, return_counts=True)
                duplicates = train_counts[train_counts > 1]
                if len(duplicates) > 0:
                    print(f"  âš ï¸ è¨“ç·´ãƒ‡ãƒ¼ã‚¿é‡è¤‡: {len(duplicates)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãŒè¤‡æ•°å›ä½¿ç”¨")
                    print(f"  æœ€å¤§ä½¿ç”¨å›æ•°: {duplicates.max()}")
                else:
                    print(f"  âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿é‡è¤‡ãªã—: å…¨ãƒ‡ãƒ¼ã‚¿ãŒ1å›ãšã¤ä½¿ç”¨")
                
                # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆé–“ã®é‡è¤‡ç¢ºèª
                overlap = np.intersect1d(train_indices, test_indices)
                if len(overlap) > 0:
                    print(f"  âš ï¸ è­¦å‘Š: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆé–“ã§{len(overlap)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãŒé‡è¤‡")
                    print(f"  é‡è¤‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¾‹: {overlap[:5]}")
                else:
                    print(f"  âœ… è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆé–“ã®é‡è¤‡ãªã—")
            
            # ãƒŸãƒ‹ãƒãƒƒãƒãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ã®è©³ç´°çµ±è¨ˆ
            if hasattr(self, '_last_train_loader'):
                train_loader = self._last_train_loader
                if train_loader and train_loader.track_usage:
                    usage_stats = train_loader.get_usage_statistics()
                    if usage_stats:
                        print(f"\nâœ… MNISTãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆï¼ˆç‹¬ç«‹ã‚µãƒ³ãƒ—ãƒ«è¿½è·¡ï¼‰:")
                        print(f"  ç·ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿æ•°: {usage_stats['total_data']}")
                        print(f"  æœ€å¤§ä½¿ç”¨å›æ•°: {usage_stats['max_usage']}")
                        print(f"  æœ€å°ä½¿ç”¨å›æ•°: {usage_stats['min_usage']}")
                        print(f"  å¹³å‡ä½¿ç”¨å›æ•°: {usage_stats['avg_usage']:.2f}")
                        
                        # ä½¿ç”¨å›æ•°åˆ†å¸ƒã‚’è¡¨ç¤º
                        usage_dist = {}
                        for count in usage_stats['usage_distribution'].values():
                            usage_dist[count] = usage_dist.get(count, 0) + 1
                        
                        print(f"  ä½¿ç”¨å›æ•°åˆ†å¸ƒ:")
                        for count, num_data in sorted(usage_dist.items()):
                            print(f"    {count}å›ä½¿ç”¨: {num_data}å€‹ã®ãƒ‡ãƒ¼ã‚¿")
                            
                        # ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ã®æ¤œè¨¼
                        # ã‚¨ãƒãƒƒã‚¯æ•°ã‚’è€ƒæ…®ã—ãŸæ­£ã—ã„åˆ¤å®š
                        expected_usage_per_data = 1  # ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ãªã‚‰å„ãƒ‡ãƒ¼ã‚¿ã¯1å›ã®ã¿ä½¿ç”¨
                        if usage_stats['max_usage'] == expected_usage_per_data and usage_stats['min_usage'] == expected_usage_per_data:
                            print(f"  âœ… å®Œå…¨ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: å…¨{usage_stats['total_data']}ã‚µãƒ³ãƒ—ãƒ«ãŒ{expected_usage_per_data}å›ãšã¤ä½¿ç”¨")
                        else:
                            # ã‚¨ãƒãƒƒã‚¯æ•°ã¨ä¸€è‡´ã™ã‚‹å ´åˆã¯æ­£å¸¸ï¼ˆã‚¨ãƒãƒƒã‚¯æ¯ã«ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
                            actual_epochs = getattr(self.hyperparams, 'epochs', 1)
                            if usage_stats['max_usage'] == actual_epochs and usage_stats['min_usage'] == actual_epochs:
                                print(f"  âœ… ã‚¨ãƒãƒƒã‚¯åˆ†å‰²ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: å„ã‚¨ãƒãƒƒã‚¯ã§ç‹¬ç«‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆ{actual_epochs}ã‚¨ãƒãƒƒã‚¯å¯¾å¿œï¼‰")
                            else:
                                print(f"  ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆ: ä½¿ç”¨å›æ•° æœ€å°{usage_stats['min_usage']} æœ€å¤§{usage_stats['max_usage']}å›")
                    else:
                        print(f"\nâš ï¸ MNISTãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆ: çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãªã—")
                else:
                    print(f"\nâš ï¸ MNISTãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆ: è¿½è·¡ç„¡åŠ¹")
            else:
                print(f"\nâš ï¸ MNISTãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆ: ãƒ­ãƒ¼ãƒ€ãƒ¼æƒ…å ±ãªã—")
            
            print(f"{'='*60}")
                
        except Exception as e:
            if not getattr(self.hyperparams, 'quiet_mode', False):
                print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çµ±è¨ˆã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

